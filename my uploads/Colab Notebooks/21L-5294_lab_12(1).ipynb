{"metadata":{"colab":{"provenance":[{"file_id":"1aLxRhHZJ5vmyt4ALCDc8nCscBCqchXp6","timestamp":1714979059975}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","import keras\n","from keras.layers import Dense,Input, InputLayer, Flatten\n","from keras.models import Sequential, Model, load_model\n","from  matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix,f1_score\n"],"metadata":{"id":"QIlzivSmDdLb","execution":{"iopub.status.busy":"2024-05-01T18:59:27.948556Z","iopub.execute_input":"2024-05-01T18:59:27.948971Z","iopub.status.idle":"2024-05-01T18:59:39.969176Z","shell.execute_reply.started":"2024-05-01T18:59:27.948942Z","shell.execute_reply":"2024-05-01T18:59:39.968196Z"},"trusted":true,"executionInfo":{"status":"ok","timestamp":1714979603108,"user_tz":-300,"elapsed":7799,"user":{"displayName":"Muhammad Laraib Akhtar BSCS 2021 FAST NU LHR","userId":"17220094101714184534"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#View some samples of the dataset\n","import random\n","plt.figure(figsize=(20,20))\n","folder=r'/kaggle/input/flowers-recognition/flowers/daisy'\n","for i in range(5):\n","    file = random.choice(os.listdir(folder))\n","    image_path= os.path.join(folder, file)\n","    img=mpimg.imread(image_path)\n","    ax=plt.subplot(1,5,i+1)\n","    ax.title.set_text(file)\n","    plt.imshow(img)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"TZhFVat7EN-b","outputId":"63339654-87be-4cee-9dfe-1c59c481e690","execution":{"iopub.status.busy":"2024-05-01T18:59:39.970918Z","iopub.execute_input":"2024-05-01T18:59:39.971442Z","iopub.status.idle":"2024-05-01T18:59:41.445850Z","shell.execute_reply.started":"2024-05-01T18:59:39.971414Z","shell.execute_reply":"2024-05-01T18:59:41.444919Z"},"trusted":true,"executionInfo":{"status":"error","timestamp":1714979643070,"user_tz":-300,"elapsed":743,"user":{"displayName":"Muhammad Laraib Akhtar BSCS 2021 FAST NU LHR","userId":"17220094101714184534"}}},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/flowers-recognition/flowers/daisy'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-69ff40b48432>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'/kaggle/input/flowers-recognition/flowers/daisy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/flowers-recognition/flowers/daisy'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x2000 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["def load_and_preprocess_data(data_dir, image_size):\n","    images = []\n","    labels = []\n","\n","    # Iterate through each folder (each class of flowers)\n","    for class_name in os.listdir(data_dir):\n","        class_dir = os.path.join(data_dir, class_name)\n","\n","        # Iterate through each image in the class folder\n","        for image_name in os.listdir(class_dir):\n","            image_path = os.path.join(class_dir, image_name)\n","\n","            # Read image and resize\n","            image = cv2.imread(image_path) #reads in BGR format\n","            #To read an image in grayscale\n","            #image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","            image = cv2.resize(image, image_size)\n","\n","            # Normalize pixel values to [0, 1]\n","            image = image.astype('float32') / 255.0\n","\n","            # Append to the lists\n","            images.append(image)\n","            labels.append(class_name)\n","\n","    # Convert lists to numpy arrays\n","    images = np.array(images)\n","    labels = np.array(labels)\n","\n","    return images, labels\n","\n"],"metadata":{"id":"1AZL6LgImj8g","execution":{"iopub.status.busy":"2024-05-01T18:59:41.446965Z","iopub.execute_input":"2024-05-01T18:59:41.447264Z","iopub.status.idle":"2024-05-01T18:59:41.454760Z","shell.execute_reply.started":"2024-05-01T18:59:41.447238Z","shell.execute_reply":"2024-05-01T18:59:41.453775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_dir = \"/kaggle/input/flowers-recognition/flowers\""],"metadata":{"id":"Tl7Zxyu-o531","execution":{"iopub.status.busy":"2024-05-01T18:59:41.456922Z","iopub.execute_input":"2024-05-01T18:59:41.457234Z","iopub.status.idle":"2024-05-01T18:59:41.464249Z","shell.execute_reply.started":"2024-05-01T18:59:41.457209Z","shell.execute_reply":"2024-05-01T18:59:41.463444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_size = (128, 128)\n","\n","images, labels = load_and_preprocess_data(dataset_dir, image_size)"],"metadata":{"id":"zLMB3VhApJuU","execution":{"iopub.status.busy":"2024-05-01T18:59:41.465478Z","iopub.execute_input":"2024-05-01T18:59:41.466094Z","iopub.status.idle":"2024-05-01T19:00:15.564742Z","shell.execute_reply.started":"2024-05-01T18:59:41.466057Z","shell.execute_reply":"2024-05-01T19:00:15.563742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WY0bknMVpiW_","outputId":"ac71c677-8dff-4c78-a175-93075bbfff54","execution":{"iopub.status.busy":"2024-05-01T19:00:15.566358Z","iopub.execute_input":"2024-05-01T19:00:15.566752Z","iopub.status.idle":"2024-05-01T19:00:15.580869Z","shell.execute_reply.started":"2024-05-01T19:00:15.566718Z","shell.execute_reply":"2024-05-01T19:00:15.579959Z"},"trusted":true},"execution_count":null,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([[[[0.1764706 , 0.17254902, 0.15294118],\n         [0.18039216, 0.18039216, 0.16078432],\n         [0.1882353 , 0.19215687, 0.16862746],\n         ...,\n         [0.20392157, 0.13333334, 0.08627451],\n         [0.20392157, 0.13333334, 0.08627451],\n         [0.20392157, 0.13333334, 0.08627451]],\n\n        [[0.1764706 , 0.1764706 , 0.15686275],\n         [0.18431373, 0.18039216, 0.16470589],\n         [0.1882353 , 0.19215687, 0.17254902],\n         ...,\n         [0.2       , 0.13333334, 0.08627451],\n         [0.20392157, 0.13333334, 0.08627451],\n         [0.20392157, 0.13725491, 0.09019608]],\n\n        [[0.18039216, 0.1764706 , 0.16078432],\n         [0.18431373, 0.1882353 , 0.16862746],\n         [0.19215687, 0.19607843, 0.17254902],\n         ...,\n         [0.2       , 0.13725491, 0.08627451],\n         [0.2       , 0.13725491, 0.08627451],\n         [0.20784314, 0.14117648, 0.09411765]],\n\n        ...,\n\n        [[0.10588235, 0.19607843, 0.32156864],\n         [0.10196079, 0.19215687, 0.3137255 ],\n         [0.09803922, 0.1882353 , 0.3137255 ],\n         ...,\n         [0.28627452, 0.2       , 0.14901961],\n         [0.28627452, 0.19607843, 0.14509805],\n         [0.28235295, 0.19607843, 0.14509805]],\n\n        [[0.10588235, 0.2       , 0.3254902 ],\n         [0.10588235, 0.2       , 0.32156864],\n         [0.10196079, 0.19607843, 0.31764707],\n         ...,\n         [0.28627452, 0.2       , 0.14901961],\n         [0.28627452, 0.2       , 0.14901961],\n         [0.28235295, 0.19607843, 0.14509805]],\n\n        [[0.10196079, 0.2       , 0.32156864],\n         [0.10196079, 0.2       , 0.32156864],\n         [0.10588235, 0.20392157, 0.3254902 ],\n         ...,\n         [0.28235295, 0.19607843, 0.14509805],\n         [0.28627452, 0.2       , 0.14901961],\n         [0.28627452, 0.2       , 0.14901961]]],\n\n\n       [[[0.14901961, 0.11372549, 0.03921569],\n         [0.13333334, 0.10980392, 0.03137255],\n         [0.10588235, 0.09411765, 0.02352941],\n         ...,\n         [0.12941177, 0.1764706 , 0.03529412],\n         [0.11372549, 0.15294118, 0.01960784],\n         [0.12156863, 0.14901961, 0.01960784]],\n\n        [[0.15294118, 0.11764706, 0.03529412],\n         [0.13725491, 0.11372549, 0.03921569],\n         [0.10196079, 0.09019608, 0.01960784],\n         ...,\n         [0.11764706, 0.16078432, 0.02745098],\n         [0.10980392, 0.13725491, 0.01568628],\n         [0.1254902 , 0.15294118, 0.02352941]],\n\n        [[0.15294118, 0.12156863, 0.03921569],\n         [0.13725491, 0.10980392, 0.03529412],\n         [0.10980392, 0.09411765, 0.01960784],\n         ...,\n         [0.09803922, 0.15294118, 0.01960784],\n         [0.11372549, 0.14509805, 0.02745098],\n         [0.12941177, 0.15686275, 0.02352941]],\n\n        ...,\n\n        [[0.03921569, 0.05098039, 0.01568628],\n         [0.03921569, 0.05098039, 0.01568628],\n         [0.04313726, 0.04705882, 0.01568628],\n         ...,\n         [0.05882353, 0.06666667, 0.01568628],\n         [0.0627451 , 0.06666667, 0.01568628],\n         [0.06666667, 0.06666667, 0.01960784]],\n\n        [[0.03529412, 0.05490196, 0.01568628],\n         [0.03529412, 0.05098039, 0.01176471],\n         [0.03137255, 0.05098039, 0.01176471],\n         ...,\n         [0.0627451 , 0.07058824, 0.01960784],\n         [0.0627451 , 0.06666667, 0.01960784],\n         [0.0627451 , 0.0627451 , 0.01568628]],\n\n        [[0.03529412, 0.05098039, 0.01568628],\n         [0.03529412, 0.05098039, 0.01176471],\n         [0.03529412, 0.05490196, 0.01568628],\n         ...,\n         [0.07058824, 0.07058824, 0.02352941],\n         [0.0627451 , 0.07058824, 0.01960784],\n         [0.07058824, 0.07058824, 0.01960784]]],\n\n\n       [[[0.627451  , 0.6431373 , 0.6509804 ],\n         [0.6313726 , 0.6431373 , 0.654902  ],\n         [0.627451  , 0.6431373 , 0.64705884],\n         ...,\n         [0.27058825, 0.3137255 , 0.1882353 ],\n         [0.2627451 , 0.3137255 , 0.19607843],\n         [0.2627451 , 0.3137255 , 0.19607843]],\n\n        [[0.6431373 , 0.654902  , 0.67058825],\n         [0.654902  , 0.6627451 , 0.68235296],\n         [0.654902  , 0.6627451 , 0.6745098 ],\n         ...,\n         [0.27058825, 0.3137255 , 0.18431373],\n         [0.27058825, 0.3137255 , 0.1882353 ],\n         [0.2627451 , 0.31764707, 0.19215687]],\n\n        [[0.6392157 , 0.654902  , 0.6666667 ],\n         [0.6509804 , 0.65882355, 0.6784314 ],\n         [0.64705884, 0.6509804 , 0.6666667 ],\n         ...,\n         [0.2627451 , 0.31764707, 0.1882353 ],\n         [0.27058825, 0.3137255 , 0.19607843],\n         [0.2627451 , 0.31764707, 0.18039216]],\n\n        ...,\n\n        [[0.7058824 , 0.6862745 , 0.59607846],\n         [0.6901961 , 0.67058825, 0.59607846],\n         [0.67058825, 0.6627451 , 0.60784316],\n         ...,\n         [0.22745098, 0.29411766, 0.15294118],\n         [0.23137255, 0.29803923, 0.15686275],\n         [0.23137255, 0.29803923, 0.15686275]],\n\n        [[0.69803923, 0.6745098 , 0.57254905],\n         [0.69411767, 0.6745098 , 0.57254905],\n         [0.6745098 , 0.6627451 , 0.59607846],\n         ...,\n         [0.22745098, 0.29803923, 0.14901961],\n         [0.23529412, 0.30588236, 0.15686275],\n         [0.23529412, 0.3019608 , 0.16078432]],\n\n        [[0.68235296, 0.6627451 , 0.52156866],\n         [0.7019608 , 0.68235296, 0.5529412 ],\n         [0.6901961 , 0.67058825, 0.5921569 ],\n         ...,\n         [0.23137255, 0.3019608 , 0.15294118],\n         [0.23529412, 0.30588236, 0.15686275],\n         [0.24313726, 0.3137255 , 0.16470589]]],\n\n\n       ...,\n\n\n       [[[0.06666667, 0.07843138, 0.09803922],\n         [0.05882353, 0.07058824, 0.09019608],\n         [0.05098039, 0.06666667, 0.09411765],\n         ...,\n         [0.25490198, 0.27450982, 0.28627452],\n         [0.24705882, 0.25882354, 0.2784314 ],\n         [0.23529412, 0.22745098, 0.25490198]],\n\n        [[0.05882353, 0.07058824, 0.09019608],\n         [0.05098039, 0.0627451 , 0.08627451],\n         [0.05098039, 0.06666667, 0.09411765],\n         ...,\n         [0.2627451 , 0.2784314 , 0.2901961 ],\n         [0.24705882, 0.25490198, 0.27450982],\n         [0.24705882, 0.23529412, 0.2627451 ]],\n\n        [[0.05098039, 0.0627451 , 0.08235294],\n         [0.04705882, 0.05882353, 0.07843138],\n         [0.05490196, 0.06666667, 0.09803922],\n         ...,\n         [0.26666668, 0.28235295, 0.29411766],\n         [0.23529412, 0.23921569, 0.2627451 ],\n         [0.23921569, 0.23137255, 0.25490198]],\n\n        ...,\n\n        [[0.05490196, 0.05490196, 0.05490196],\n         [0.05098039, 0.04705882, 0.04705882],\n         [0.07843138, 0.07450981, 0.08627451],\n         ...,\n         [0.24705882, 0.24313726, 0.2627451 ],\n         [0.21176471, 0.20784314, 0.22745098],\n         [0.1764706 , 0.17254902, 0.19215687]],\n\n        [[0.0627451 , 0.0627451 , 0.0627451 ],\n         [0.09019608, 0.08627451, 0.08627451],\n         [0.16078432, 0.15686275, 0.16078432],\n         ...,\n         [0.23921569, 0.23529412, 0.25490198],\n         [0.20392157, 0.2       , 0.21960784],\n         [0.17254902, 0.16862746, 0.1882353 ]],\n\n        [[0.07058824, 0.07058824, 0.07843138],\n         [0.12156863, 0.11764706, 0.11372549],\n         [0.23921569, 0.23921569, 0.22745098],\n         ...,\n         [0.23137255, 0.22352941, 0.24705882],\n         [0.19215687, 0.1882353 , 0.20784314],\n         [0.16078432, 0.15686275, 0.1764706 ]]],\n\n\n       [[[0.2509804 , 0.31764707, 0.41960785],\n         [0.2509804 , 0.31764707, 0.41960785],\n         [0.2627451 , 0.34117648, 0.4392157 ],\n         ...,\n         [0.40784314, 0.5411765 , 0.6901961 ],\n         [0.43137255, 0.5647059 , 0.69411767],\n         [0.4627451 , 0.5882353 , 0.70980394]],\n\n        [[0.24705882, 0.3137255 , 0.41568628],\n         [0.2509804 , 0.31764707, 0.41960785],\n         [0.2627451 , 0.34117648, 0.4392157 ],\n         ...,\n         [0.41960785, 0.5529412 , 0.69803923],\n         [0.43529412, 0.57254905, 0.69803923],\n         [0.47058824, 0.6       , 0.7176471 ]],\n\n        [[0.24313726, 0.30980393, 0.4117647 ],\n         [0.25882354, 0.3254902 , 0.42745098],\n         [0.2627451 , 0.34117648, 0.43529412],\n         ...,\n         [0.43137255, 0.5686275 , 0.7019608 ],\n         [0.4392157 , 0.5764706 , 0.7019608 ],\n         [0.4745098 , 0.6       , 0.72156864]],\n\n        ...,\n\n        [[0.12941177, 0.12941177, 0.17254902],\n         [0.10196079, 0.09411765, 0.13725491],\n         [0.11372549, 0.1254902 , 0.19215687],\n         ...,\n         [0.28627452, 0.35686275, 0.44313726],\n         [0.25490198, 0.3254902 , 0.4117647 ],\n         [0.26666668, 0.3372549 , 0.42352942]],\n\n        [[0.10196079, 0.09411765, 0.14117648],\n         [0.10196079, 0.09803922, 0.13333334],\n         [0.13725491, 0.14117648, 0.20784314],\n         ...,\n         [0.27450982, 0.34117648, 0.43137255],\n         [0.2509804 , 0.31764707, 0.40784314],\n         [0.2509804 , 0.31764707, 0.40392157]],\n\n        [[0.09803922, 0.08235294, 0.13725491],\n         [0.10588235, 0.10196079, 0.13725491],\n         [0.12941177, 0.12941177, 0.18431373],\n         ...,\n         [0.25882354, 0.32156864, 0.4117647 ],\n         [0.2509804 , 0.3137255 , 0.40392157],\n         [0.24313726, 0.30588236, 0.39607844]]],\n\n\n       [[[0.64705884, 0.69411767, 0.6666667 ],\n         [0.6509804 , 0.7019608 , 0.6666667 ],\n         [0.6745098 , 0.70980394, 0.68235296],\n         ...,\n         [0.63529414, 0.69803923, 0.65882355],\n         [0.6392157 , 0.6901961 , 0.6509804 ],\n         [0.61960787, 0.6745098 , 0.6392157 ]],\n\n        [[0.654902  , 0.69803923, 0.67058825],\n         [0.6627451 , 0.7058824 , 0.6745098 ],\n         [0.6745098 , 0.72156864, 0.69411767],\n         ...,\n         [0.6431373 , 0.7058824 , 0.6627451 ],\n         [0.6313726 , 0.7019608 , 0.654902  ],\n         [0.6313726 , 0.68235296, 0.63529414]],\n\n        [[0.654902  , 0.70980394, 0.68235296],\n         [0.6784314 , 0.7254902 , 0.69411767],\n         [0.68235296, 0.7294118 , 0.7019608 ],\n         ...,\n         [0.6392157 , 0.7058824 , 0.6627451 ],\n         [0.64705884, 0.69803923, 0.65882355],\n         [0.627451  , 0.69803923, 0.63529414]],\n\n        ...,\n\n        [[0.6117647 , 0.28235295, 0.39215687],\n         [0.627451  , 0.32941177, 0.4117647 ],\n         [0.63529414, 0.33333334, 0.42745098],\n         ...,\n         [0.4862745 , 0.3882353 , 0.27058825],\n         [0.4745098 , 0.36078432, 0.2509804 ],\n         [0.48235294, 0.3647059 , 0.29803923]],\n\n        [[0.6039216 , 0.30588236, 0.4       ],\n         [0.60784316, 0.30588236, 0.39215687],\n         [0.627451  , 0.3372549 , 0.42352942],\n         ...,\n         [0.47058824, 0.33333334, 0.24705882],\n         [0.49019608, 0.3647059 , 0.28235295],\n         [0.45882353, 0.36078432, 0.24313726]],\n\n        [[0.6       , 0.3372549 , 0.41960785],\n         [0.61960787, 0.3254902 , 0.42352942],\n         [0.6156863 , 0.34509805, 0.42745098],\n         ...,\n         [0.48235294, 0.34901962, 0.25882354],\n         [0.4745098 , 0.3647059 , 0.23921569],\n         [0.44705883, 0.3647059 , 0.23921569]]]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","# Convert class labels to one-hot encoded vectors\n","label_encoder = LabelEncoder()\n","encoded_class_names = label_encoder.fit_transform(labels)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:15.582086Z","iopub.execute_input":"2024-05-01T19:00:15.582458Z","iopub.status.idle":"2024-05-01T19:00:15.592295Z","shell.execute_reply.started":"2024-05-01T19:00:15.582422Z","shell.execute_reply":"2024-05-01T19:00:15.591447Z"},"trusted":true,"id":"_y1KM8AFtZj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_class_names"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:15.593326Z","iopub.execute_input":"2024-05-01T19:00:15.593603Z","iopub.status.idle":"2024-05-01T19:00:15.603425Z","shell.execute_reply.started":"2024-05-01T19:00:15.593580Z","shell.execute_reply":"2024-05-01T19:00:15.602489Z"},"trusted":true,"id":"gZovoFbFtZj-","outputId":"39b9cfb4-f492-4b03-f904-d44b8b807bac"},"execution_count":null,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, ..., 2, 2, 2])"},"metadata":{}}]},{"cell_type":"code","source":["labels"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:15.604577Z","iopub.execute_input":"2024-05-01T19:00:15.604854Z","iopub.status.idle":"2024-05-01T19:00:15.613412Z","shell.execute_reply.started":"2024-05-01T19:00:15.604831Z","shell.execute_reply":"2024-05-01T19:00:15.612554Z"},"trusted":true,"id":"ma_sOY0ntZkC","outputId":"6d0a31b8-5084-4e2d-f863-edb0e4c40eba"},"execution_count":null,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array(['dandelion', 'dandelion', 'dandelion', ..., 'rose', 'rose', 'rose'],\n      dtype='<U9')"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","\n","# Split dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(images, encoded_class_names, test_size=0.33, random_state=42)\n","\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)\n","X_train = np.array(X_train)\n","X_test = np.array(X_test)\n","\n","# Check the shapes of the datasets\n","print(\"Train images shape:\", X_train.shape)\n","print(\"Train labels shape:\", X_test.shape)\n","print(\"Validation images shape:\", y_train.shape)\n","print(\"Validation labels shape:\", y_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0B1iIcQIom2H","outputId":"9ecf02bd-df92-4ef7-8380-5fbd6eafe8f3","execution":{"iopub.status.busy":"2024-05-01T19:00:15.616770Z","iopub.execute_input":"2024-05-01T19:00:15.617370Z","iopub.status.idle":"2024-05-01T19:00:16.191877Z","shell.execute_reply.started":"2024-05-01T19:00:15.617345Z","shell.execute_reply":"2024-05-01T19:00:16.190913Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Train images shape: (2892, 128, 128, 3)\nTrain labels shape: (1425, 128, 128, 3)\nValidation images shape: (2892,)\nValidation labels shape: (1425,)\n","output_type":"stream"}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5v6gFNIHh9L","outputId":"c5e9fa29-e098-4096-dd54-0205621900cd","execution":{"iopub.status.busy":"2024-05-01T19:00:16.193083Z","iopub.execute_input":"2024-05-01T19:00:16.193476Z","iopub.status.idle":"2024-05-01T19:00:16.202294Z","shell.execute_reply.started":"2024-05-01T19:00:16.193443Z","shell.execute_reply":"2024-05-01T19:00:16.201347Z"},"trusted":true},"execution_count":null,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 4, ..., 4, 2, 1])"},"metadata":{}}]},{"cell_type":"code","source":["model = keras.Sequential([\n","    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n","    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n","    keras.layers.Dropout(0.25),\n","    keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    keras.layers.Conv2D(256, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n","    keras.layers.Dropout(0.25),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.GlobalAveragePooling2D(),\n","    keras.layers.Dense(256, activation='relu'),\n","    keras.layers.Dropout(0.25),\n","    keras.layers.Dense(5, activation='softmax')\n","])\n","model.summary()"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:16.203649Z","iopub.execute_input":"2024-05-01T19:00:16.204197Z","iopub.status.idle":"2024-05-01T19:00:16.947109Z","shell.execute_reply.started":"2024-05-01T19:00:16.204164Z","shell.execute_reply":"2024-05-01T19:00:16.946286Z"},"trusted":true,"id":"UorFKPBytZkJ","outputId":"5462fd6e-0888-4fd3-f30d-c974acf23b23"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,285\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m456,517\u001b[0m (1.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">456,517</span> (1.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m456,005\u001b[0m (1.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">456,005</span> (1.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":["# Compile the model\n","initial_lr = 0.0001\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_lr, decay_steps=10000, decay_rate=0.9\n",")\n","optimizer = Adam(learning_rate=lr_schedule)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:16.948149Z","iopub.execute_input":"2024-05-01T19:00:16.948430Z","iopub.status.idle":"2024-05-01T19:00:16.964103Z","shell.execute_reply.started":"2024-05-01T19:00:16.948381Z","shell.execute_reply":"2024-05-01T19:00:16.963241Z"},"trusted":true,"id":"C6qu3zh_tZkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n","\n","history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:00:16.965353Z","iopub.execute_input":"2024-05-01T19:00:16.965991Z","iopub.status.idle":"2024-05-01T19:02:28.693302Z","shell.execute_reply.started":"2024-05-01T19:00:16.965957Z","shell.execute_reply":"2024-05-01T19:02:28.692206Z"},"trusted":true,"id":"pgrBFeU5tZkM","outputId":"bb38bcfb-542e-4e6c-ec2c-e5e0f504eef2"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2024-05-01 19:00:23.223649: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2175: 3.31527, expected 2.86333\n2024-05-01 19:00:23.223730: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8832: 3.04387, expected 2.59193\n2024-05-01 19:00:23.223740: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8960: 3.285, expected 2.83305\n2024-05-01 19:00:23.223751: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9600: 3.16471, expected 2.71277\n2024-05-01 19:00:23.223769: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12032: 3.08921, expected 2.63726\n2024-05-01 19:00:23.223790: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15360: 3.30205, expected 2.8501\n2024-05-01 19:00:23.223880: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32768: 4.65504, expected 3.81534\n2024-05-01 19:00:23.223895: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32770: 6.82215, expected 5.98245\n2024-05-01 19:00:23.223906: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32771: 6.43559, expected 5.5959\n2024-05-01 19:00:23.223916: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32772: 5.25099, expected 4.41129\n2024-05-01 19:00:23.231495: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:23.231538: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:23.231546: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:23.231553: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:23.231560: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:23.231576: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-01 19:00:23.570574: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2175: 3.31527, expected 2.86333\n2024-05-01 19:00:23.570662: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8832: 3.04387, expected 2.59193\n2024-05-01 19:00:23.570672: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8960: 3.285, expected 2.83305\n2024-05-01 19:00:23.570682: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9600: 3.16471, expected 2.71277\n2024-05-01 19:00:23.570699: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12032: 3.08921, expected 2.63726\n2024-05-01 19:00:23.570720: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15360: 3.30205, expected 2.8501\n2024-05-01 19:00:23.570795: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32768: 4.65504, expected 3.81534\n2024-05-01 19:00:23.570803: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32770: 6.82215, expected 5.98245\n2024-05-01 19:00:23.570810: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32771: 6.43559, expected 5.5959\n2024-05-01 19:00:23.570817: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32772: 5.25099, expected 4.41129\n2024-05-01 19:00:23.578400: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:23.578445: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:23.578459: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:23.578472: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:23.578487: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:23.578508: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 5/73\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.2465 - loss: 1.6160","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1714590030.125020     113 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m71/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3560 - loss: 1.4287","output_type":"stream"},{"name":"stderr","text":"2024-05-01 19:00:34.260228: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16384: 4.02921, expected 3.30225\n2024-05-01 19:00:34.260283: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16385: 5.90096, expected 5.17401\n2024-05-01 19:00:34.260303: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16387: 4.91115, expected 4.1842\n2024-05-01 19:00:34.260312: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16388: 4.45818, expected 3.73122\n2024-05-01 19:00:34.260320: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16389: 4.77732, expected 4.05036\n2024-05-01 19:00:34.260327: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16390: 4.28491, expected 3.55796\n2024-05-01 19:00:34.260334: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16391: 3.78731, expected 3.06035\n2024-05-01 19:00:34.260342: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16392: 3.9929, expected 3.26595\n2024-05-01 19:00:34.260349: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16393: 3.57166, expected 2.8447\n2024-05-01 19:00:34.260357: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16394: 4.56859, expected 3.84163\n2024-05-01 19:00:34.262249: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[9,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:34.262280: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:34.262295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:34.262308: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:34.262323: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:34.262343: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-01 19:00:34.330259: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16384: 4.02921, expected 3.30225\n2024-05-01 19:00:34.330306: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16385: 5.90096, expected 5.17401\n2024-05-01 19:00:34.330323: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16387: 4.91115, expected 4.1842\n2024-05-01 19:00:34.330341: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16388: 4.45818, expected 3.73122\n2024-05-01 19:00:34.330353: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16389: 4.77732, expected 4.05036\n2024-05-01 19:00:34.330364: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16390: 4.28491, expected 3.55796\n2024-05-01 19:00:34.330374: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16391: 3.78731, expected 3.06035\n2024-05-01 19:00:34.330385: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16392: 3.9929, expected 3.26595\n2024-05-01 19:00:34.330410: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16393: 3.57166, expected 2.8447\n2024-05-01 19:00:34.330424: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16394: 4.56859, expected 3.84163\n2024-05-01 19:00:34.332316: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[9,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:34.332348: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:34.332363: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:34.332380: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:34.332390: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:34.332423: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.3571 - loss: 1.4265","output_type":"stream"},{"name":"stderr","text":"2024-05-01 19:00:39.919303: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.34921, expected 2.46525\n2024-05-01 19:00:39.919362: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.92983, expected 5.04587\n2024-05-01 19:00:39.919371: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.86817, expected 4.98421\n2024-05-01 19:00:39.919379: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.9159, expected 4.03194\n2024-05-01 19:00:39.919387: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.84035, expected 3.95638\n2024-05-01 19:00:39.919404: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 4.60006, expected 3.7161\n2024-05-01 19:00:39.919412: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.34646, expected 3.4625\n2024-05-01 19:00:39.919419: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 3.91292, expected 3.02896\n2024-05-01 19:00:39.919427: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 3.36396, expected 2.47999\n2024-05-01 19:00:39.919434: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 3.38792, expected 2.50396\n2024-05-01 19:00:39.919450: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[3,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:39.919458: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:39.919465: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:39.919472: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:39.919478: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:39.919489: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-01 19:00:39.951021: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.34921, expected 2.46525\n2024-05-01 19:00:39.951074: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.92983, expected 5.04587\n2024-05-01 19:00:39.951083: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.86817, expected 4.98421\n2024-05-01 19:00:39.951091: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.9159, expected 4.03194\n2024-05-01 19:00:39.951098: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.84035, expected 3.95638\n2024-05-01 19:00:39.951106: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 4.60006, expected 3.7161\n2024-05-01 19:00:39.951113: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.34646, expected 3.4625\n2024-05-01 19:00:39.951121: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 3.91292, expected 3.02896\n2024-05-01 19:00:39.951128: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 3.36396, expected 2.47999\n2024-05-01 19:00:39.951135: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 3.38792, expected 2.50396\n2024-05-01 19:00:39.951151: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[3,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:00:39.951159: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:00:39.951166: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:00:39.951172: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:00:39.951179: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:00:39.951189: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 144ms/step - accuracy: 0.3576 - loss: 1.4254 - val_accuracy: 0.3368 - val_loss: 1.4187\nEpoch 2/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4485 - loss: 1.2661 - val_accuracy: 0.4508 - val_loss: 1.2920\nEpoch 3/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.4652 - loss: 1.2154 - val_accuracy: 0.3558 - val_loss: 1.5219\nEpoch 4/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5010 - loss: 1.1586 - val_accuracy: 0.4059 - val_loss: 1.5680\nEpoch 5/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5597 - loss: 1.0742 - val_accuracy: 0.4421 - val_loss: 1.3301\nEpoch 6/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5710 - loss: 1.0612 - val_accuracy: 0.5026 - val_loss: 1.1859\nEpoch 7/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6126 - loss: 1.0194 - val_accuracy: 0.4594 - val_loss: 1.2871\nEpoch 8/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6256 - loss: 0.9677 - val_accuracy: 0.5026 - val_loss: 1.2179\nEpoch 9/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6297 - loss: 0.9563 - val_accuracy: 0.5596 - val_loss: 1.1065\nEpoch 10/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6313 - loss: 0.9343 - val_accuracy: 0.6183 - val_loss: 0.9152\nEpoch 11/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6578 - loss: 0.8683 - val_accuracy: 0.5492 - val_loss: 1.0440\nEpoch 12/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6705 - loss: 0.8502 - val_accuracy: 0.5216 - val_loss: 1.1899\nEpoch 13/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6546 - loss: 0.9037 - val_accuracy: 0.5941 - val_loss: 0.9591\nEpoch 14/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7023 - loss: 0.8067 - val_accuracy: 0.6287 - val_loss: 0.9779\nEpoch 15/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6795 - loss: 0.8151 - val_accuracy: 0.6442 - val_loss: 0.8893\nEpoch 16/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7206 - loss: 0.7583 - val_accuracy: 0.6131 - val_loss: 1.0339\nEpoch 17/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6757 - loss: 0.7954 - val_accuracy: 0.6408 - val_loss: 0.9422\nEpoch 18/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7114 - loss: 0.7524 - val_accuracy: 0.6097 - val_loss: 1.0799\nEpoch 19/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7067 - loss: 0.7635 - val_accuracy: 0.6235 - val_loss: 1.0071\nEpoch 20/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7108 - loss: 0.7364 - val_accuracy: 0.6563 - val_loss: 0.8493\nEpoch 21/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7533 - loss: 0.6987 - val_accuracy: 0.6874 - val_loss: 0.8308\nEpoch 22/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7211 - loss: 0.7189 - val_accuracy: 0.6718 - val_loss: 0.8466\nEpoch 23/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7388 - loss: 0.7046 - val_accuracy: 0.6373 - val_loss: 0.9672\nEpoch 24/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7622 - loss: 0.6510 - val_accuracy: 0.6287 - val_loss: 0.9978\nEpoch 25/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7655 - loss: 0.6186 - val_accuracy: 0.6891 - val_loss: 0.8369\nEpoch 26/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7577 - loss: 0.6529 - val_accuracy: 0.6028 - val_loss: 1.1508\nEpoch 27/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7532 - loss: 0.6484 - val_accuracy: 0.7150 - val_loss: 0.8105\nEpoch 28/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7609 - loss: 0.6303 - val_accuracy: 0.6926 - val_loss: 0.8561\nEpoch 29/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7788 - loss: 0.5801 - val_accuracy: 0.6615 - val_loss: 0.8809\nEpoch 30/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7728 - loss: 0.5934 - val_accuracy: 0.6339 - val_loss: 1.0870\nEpoch 31/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7765 - loss: 0.5919 - val_accuracy: 0.7168 - val_loss: 0.8094\nEpoch 32/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8010 - loss: 0.5488 - val_accuracy: 0.7323 - val_loss: 0.7917\nEpoch 33/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8153 - loss: 0.5342 - val_accuracy: 0.7150 - val_loss: 0.7997\nEpoch 34/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8101 - loss: 0.5164 - val_accuracy: 0.7098 - val_loss: 0.7950\nEpoch 35/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8125 - loss: 0.5330 - val_accuracy: 0.7323 - val_loss: 0.7254\nEpoch 36/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8167 - loss: 0.4974 - val_accuracy: 0.7116 - val_loss: 0.8013\nEpoch 37/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8266 - loss: 0.4653 - val_accuracy: 0.6839 - val_loss: 0.8794\nEpoch 38/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8247 - loss: 0.4867 - val_accuracy: 0.7150 - val_loss: 0.7526\nEpoch 39/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8391 - loss: 0.4544 - val_accuracy: 0.7081 - val_loss: 0.8330\nEpoch 40/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8364 - loss: 0.4579 - val_accuracy: 0.6978 - val_loss: 0.8177\nEpoch 41/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8352 - loss: 0.4617 - val_accuracy: 0.6857 - val_loss: 0.8481\nEpoch 42/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8392 - loss: 0.4348 - val_accuracy: 0.7081 - val_loss: 0.9599\nEpoch 43/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8431 - loss: 0.4286 - val_accuracy: 0.6598 - val_loss: 1.0070\nEpoch 44/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8229 - loss: 0.4753 - val_accuracy: 0.7219 - val_loss: 0.7534\nEpoch 45/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8805 - loss: 0.3478 - val_accuracy: 0.7254 - val_loss: 0.8226\nEpoch 46/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8530 - loss: 0.3891 - val_accuracy: 0.7012 - val_loss: 0.8477\nEpoch 47/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8683 - loss: 0.3585 - val_accuracy: 0.7392 - val_loss: 0.7976\nEpoch 48/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8690 - loss: 0.3565 - val_accuracy: 0.6373 - val_loss: 1.2505\nEpoch 49/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8530 - loss: 0.4053 - val_accuracy: 0.6287 - val_loss: 1.3298\nEpoch 50/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8640 - loss: 0.4003 - val_accuracy: 0.7306 - val_loss: 0.8347\n","output_type":"stream"}]},{"cell_type":"code","source":["predicted_labels = model.predict(X_test)\n","predicted_labels = np.argmax(predicted_labels, axis=1)\n","#predicted_class_names = label_encoder.inverse_transform(predicted_labels)\n","\n","f1 = f1_score(y_test, predicted_labels, average='macro')\n","report = classification_report(y_test, predicted_labels)\n","\n","print(\"F1 Score:\", f1)\n","print(\"Classification Report:\")\n","print(report)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:02:28.695072Z","iopub.execute_input":"2024-05-01T19:02:28.695443Z","iopub.status.idle":"2024-05-01T19:02:31.378092Z","shell.execute_reply.started":"2024-05-01T19:02:28.695413Z","shell.execute_reply":"2024-05-01T19:02:31.377102Z"},"trusted":true,"id":"hN_mEdKTtZkN","outputId":"3a693b6b-21a3-47fd-d25e-ae7e236671ee"},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[1m36/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step","output_type":"stream"},{"name":"stderr","text":"2024-05-01 19:02:30.304956: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16384: 4.17829, expected 3.61709\n2024-05-01 19:02:30.305010: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16391: 3.8394, expected 3.2782\n2024-05-01 19:02:30.305026: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16392: 4.02634, expected 3.46514\n2024-05-01 19:02:30.305044: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16393: 3.87915, expected 3.31795\n2024-05-01 19:02:30.305055: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16416: 4.5964, expected 4.0352\n2024-05-01 19:02:30.305067: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16463: 4.5263, expected 3.9651\n2024-05-01 19:02:30.305078: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16464: 3.85564, expected 3.29444\n2024-05-01 19:02:30.305088: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16511: 3.98259, expected 3.42139\n2024-05-01 19:02:30.305103: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 17151: 4.57736, expected 4.01616\n2024-05-01 19:02:30.305114: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 17279: 4.5641, expected 4.0029\n2024-05-01 19:02:30.309242: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[17,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[17,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:02:30.309273: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:02:30.309286: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:02:30.309300: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:02:30.309312: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:02:30.309330: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-01 19:02:30.415536: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16384: 4.17829, expected 3.61709\n2024-05-01 19:02:30.415591: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16391: 3.8394, expected 3.2782\n2024-05-01 19:02:30.415605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16392: 4.02634, expected 3.46514\n2024-05-01 19:02:30.415621: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16393: 3.87915, expected 3.31795\n2024-05-01 19:02:30.415635: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16416: 4.5964, expected 4.0352\n2024-05-01 19:02:30.415647: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16463: 4.5263, expected 3.9651\n2024-05-01 19:02:30.415657: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16464: 3.85564, expected 3.29444\n2024-05-01 19:02:30.415669: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16511: 3.98259, expected 3.42139\n2024-05-01 19:02:30.415686: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 17151: 4.57736, expected 4.01616\n2024-05-01 19:02:30.415701: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 17279: 4.5641, expected 4.0029\n2024-05-01 19:02:30.419335: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[17,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[17,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-01 19:02:30.419368: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-01 19:02:30.419379: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-01 19:02:30.419390: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-01 19:02:30.419413: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-01 19:02:30.419436: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\nF1 Score: 0.7704130154229445\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.69      0.86      0.76       268\n           1       0.87      0.80      0.83       361\n           2       0.69      0.68      0.69       253\n           3       0.81      0.83      0.82       239\n           4       0.81      0.70      0.75       304\n\n    accuracy                           0.77      1425\n   macro avg       0.77      0.77      0.77      1425\nweighted avg       0.78      0.77      0.77      1425\n\n","output_type":"stream"}]}]}