{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db953435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Episode 1 ---\n",
      "Step 3: S13 --down--> S23, R=100\n",
      "    Q updated: 0.00 -> 10.00\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 10.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 0.00\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 2 ---\n",
      "Step 5: S22 --right--> S23, R=100\n",
      "    Q updated: 0.00 -> 10.00\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 10.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 0.00\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 10.00\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 3 ---\n",
      "Step 1: S13 --down--> S23, R=100\n",
      "    Q updated: 10.00 -> 19.00\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 0.00\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 10.00\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 4 ---\n",
      "Step 19: S21 --right--> S22, R=0\n",
      "    Q updated: 0.00 -> 0.90\n",
      "Step 20: S22 --right--> S23, R=100\n",
      "    Q updated: 10.00 -> 19.00\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 0.90\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 19.00\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 5 ---\n",
      "Step 1: S21 --right--> S22, R=0\n",
      "    Q updated: 0.90 -> 2.52\n",
      "Step 2: S22 --right--> S23, R=100\n",
      "    Q updated: 19.00 -> 27.10\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 2.52\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 27.10\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 6 ---\n",
      "Step 1: S22 --right--> S23, R=100\n",
      "    Q updated: 27.10 -> 34.39\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 2.52\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 34.39\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 7 ---\n",
      "Step 1: S22 --right--> S23, R=100\n",
      "    Q updated: 34.39 -> 40.95\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 2.52\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 40.95\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 8 ---\n",
      "Step 1: S21 --right--> S22, R=0\n",
      "    Q updated: 2.52 -> 5.95\n",
      "Step 2: S22 --right--> S23, R=100\n",
      "    Q updated: 40.95 -> 46.86\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.00\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 5.95\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 46.86\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 9 ---\n",
      "Step 1: S11 --down--> S21, R=0\n",
      "    Q updated: 0.00 -> 0.54\n",
      "Step 2: S21 --right--> S22, R=0\n",
      "    Q updated: 5.95 -> 9.58\n",
      "Step 3: S22 --right--> S23, R=100\n",
      "    Q updated: 46.86 -> 52.17\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 0.54\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 9.58\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 52.17\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "--- Episode 10 ---\n",
      "Step 1: S11 --down--> S21, R=0\n",
      "    Q updated: 0.54 -> 1.34\n",
      "Step 2: S21 --right--> S22, R=0\n",
      "    Q updated: 9.58 -> 13.31\n",
      "Step 3: S22 --right--> S23, R=100\n",
      "    Q updated: 52.17 -> 56.95\n",
      "Reached goal: S23\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 1.34\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 13.31\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 56.95\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "=== Q-Table ===\n",
      "S11:\n",
      "  down: 1.34\n",
      "  right: 0.00\n",
      "S12:\n",
      "  down: 0.00\n",
      "  left: 0.00\n",
      "  right: 0.00\n",
      "S13:\n",
      "  down: 19.00\n",
      "  left: 0.00\n",
      "S21:\n",
      "  up: 0.00\n",
      "  right: 13.31\n",
      "S22:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "  right: 56.95\n",
      "S23:\n",
      "  up: 0.00\n",
      "  left: 0.00\n",
      "\n",
      "=== Estimated V*(s) and π*(s) ===\n",
      "S11: V* = 1.34, π* = down\n",
      "S12: V* = 0.00, π* = down\n",
      "S13: V* = 19.00, π* = down\n",
      "S21: V* = 13.31, π* = right\n",
      "S22: V* = 56.95, π* = right\n",
      "\n",
      "=== Demonstrating Policy from S11 ===\n",
      "S11 -> S21 -> S22 -> S23\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.rows = 2\n",
    "        self.cols = 3\n",
    "        self.goal = (1, 2)  # S23\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        self.state = (0, 0)\n",
    "\n",
    "    def reset(self):\n",
    "        while True:\n",
    "            state = (random.randint(0, self.rows - 1), random.randint(0, self.cols - 1))\n",
    "            if state != self.goal:\n",
    "                self.state = state\n",
    "                return state\n",
    "\n",
    "    def get_valid_actions(self, state):\n",
    "        row, col = state\n",
    "        valid = []\n",
    "        if row > 0:\n",
    "            valid.append(\"up\")\n",
    "        if row < self.rows - 1:\n",
    "            valid.append(\"down\")\n",
    "        if col > 0:\n",
    "            valid.append(\"left\")\n",
    "        if col < self.cols - 1:\n",
    "            valid.append(\"right\")\n",
    "        return valid\n",
    "\n",
    "    def step(self, action):\n",
    "        row, col = self.state\n",
    "        if action == \"up\" and row > 0:\n",
    "            row -= 1\n",
    "        elif action == \"down\" and row < self.rows - 1:\n",
    "            row += 1\n",
    "        elif action == \"left\" and col > 0:\n",
    "            col -= 1\n",
    "        elif action == \"right\" and col < self.cols - 1:\n",
    "            col += 1\n",
    "\n",
    "        next_state = (row, col)\n",
    "        reward = 100 if next_state == self.goal and self.state in [(0, 2), (1, 1)] else 0\n",
    "        done = (next_state == self.goal)\n",
    "        self.state = next_state\n",
    "        return next_state, reward, done\n",
    "\n",
    "def q_learning(env, episodes=10, gamma=0.9, alpha=0.1, epsilon=0.1):\n",
    "    Q = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = env.reset()\n",
    "        print(f\"\\n--- Episode {ep + 1} ---\")\n",
    "        step = 0\n",
    "        while True:\n",
    "            valid_actions = env.get_valid_actions(state)\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                action = max(valid_actions, key=lambda a: Q[(state, a)])\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_valid = env.get_valid_actions(next_state)\n",
    "            max_q_next = max([Q[(next_state, a)] for a in next_valid], default=0)\n",
    "            old_q = Q[(state, action)]\n",
    "            new_q = (1 - alpha) * old_q + alpha * (reward + gamma * max_q_next)\n",
    "\n",
    "            if abs(new_q - old_q) > 1e-5:  # Only print if Q-value changes\n",
    "                Q[(state, action)] = new_q\n",
    "                print(f\"Step {step + 1}: S{state[0]+1}{state[1]+1} --{action}--> S{next_state[0]+1}{next_state[1]+1}, R={reward}\")\n",
    "                print(f\"    Q updated: {old_q:.2f} -> {new_q:.2f}\")\n",
    "            else:\n",
    "                Q[(state, action)] = new_q  # still update silently\n",
    "\n",
    "            state = next_state\n",
    "            step += 1\n",
    "            if done:\n",
    "                print(f\"Reached goal: S{next_state[0]+1}{next_state[1]+1}\")\n",
    "                break\n",
    "        print_q_table(Q)  # Q-table after each episode\n",
    "    return Q\n",
    "\n",
    "\n",
    "\n",
    "def print_q_table(Q):\n",
    "    print(\"\\n=== Q-Table ===\")\n",
    "    states = [(0,0), (0,1), (0,2), (1,0), (1,1), (1,2)]\n",
    "    for state in states:\n",
    "        valid = GridWorld().get_valid_actions(state)\n",
    "        state_label = f\"S{state[0]+1}{state[1]+1}\"\n",
    "        print(f\"{state_label}:\")\n",
    "        for action in valid:\n",
    "            print(f\"  {action}: {Q[(state, action)]:.2f}\")\n",
    "\n",
    "def demonstrate_policy(env, Q):\n",
    "    print(\"\\n=== Demonstrating Policy from S11 ===\")\n",
    "    state = (0, 0)\n",
    "    env.state = state\n",
    "    path = [f\"S{state[0]+1}{state[1]+1}\"]\n",
    "    while state != env.goal:\n",
    "        actions = env.get_valid_actions(state)\n",
    "        action = max(actions, key=lambda a: Q[(state, a)])\n",
    "        next_state, reward, done = env.step(action)\n",
    "        path.append(f\"S{next_state[0]+1}{next_state[1]+1}\")\n",
    "        state = next_state\n",
    "    print(\" -> \".join(path))\n",
    "\n",
    "def print_value_function(Q):\n",
    "    print(\"\\n=== Estimated V*(s) and π*(s) ===\")\n",
    "    states = [(0,0), (0,1), (0,2), (1,0), (1,1)]\n",
    "    for state in states:\n",
    "        actions = GridWorld().get_valid_actions(state)\n",
    "        if not actions:\n",
    "            continue\n",
    "        values = {a: Q[(state, a)] for a in actions}\n",
    "        best_action = max(values, key=values.get)\n",
    "        best_value = values[best_action]\n",
    "        state_label = f\"S{state[0]+1}{state[1]+1}\"\n",
    "        print(f\"{state_label}: V* = {best_value:.2f}, π* = {best_action}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = GridWorld()\n",
    "    Q = q_learning(env, episodes=10)\n",
    "    print_q_table(Q)\n",
    "    print_value_function(Q)\n",
    "    demonstrate_policy(env, Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545884c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
